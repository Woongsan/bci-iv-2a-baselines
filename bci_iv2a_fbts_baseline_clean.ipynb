{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qYvvruiiXXhk",
    "outputId": "1a909303-0fe5-49c3-bc8b-d6cf5cc2323f"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 0. 安装依赖（≈ 30 s）—— mne 1.7.0 + braindecode 0.8.1 + skorch\n",
    "#    ▶ torch/torchvision/torchaudio 已随 Colab 自带 CUDA-11 版本，\n",
    "#      不要再升级到 2.7.* 之类的非官方包，以免和 fastai 冲突\n",
    "# ===============================================================\n",
    "!pip -q install --upgrade mne==1.7.0 braindecode==0.8.1 skorch==0.15.0\n",
    "\n",
    "# ===============================================================\n",
    "# 1. 基础 import\n",
    "# ===============================================================\n",
    "import os, urllib.request, numpy as np, scipy.io as sio, torch, matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.datasets import create_from_X_y          # ← 新路径\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1-A. 工具函数\n",
    "# ---------------------------------------------------------------\n",
    "def load_bci_2a(mat_path, picks=22, t0=2.0, t1=6.0):\n",
    "    \"\"\"读取 BCI-IV-2a *单个* A0xT.mat, 返回\n",
    "       X: (n_trial, picks, 1000) float32\n",
    "       y: (n_trial,) int64  0-3\n",
    "       fs: 采样率 (250)\n",
    "    \"\"\"\n",
    "    mat   = sio.loadmat(mat_path)\n",
    "    segs, labels = [], []\n",
    "    for sess in mat['data'][0]:\n",
    "        y_run = sess['y'].item().squeeze()\n",
    "        if y_run.size == 0:          # 空 run\n",
    "            continue\n",
    "        trials = sess['trial'].item().squeeze()\n",
    "        X_raw  = sess['X'].item().T[:picks]   # 取前 22 条 EEG\n",
    "        fs     = int(sess['fs'].item())\n",
    "        win0   = int(t0*fs)                  # 2 s cue\n",
    "        win1   = int(t1*fs)                  # +4 s 运动想象\n",
    "        for st, lab in zip(trials[y_run > 0], y_run[y_run > 0] - 1):\n",
    "            end = st + win1\n",
    "            if end <= X_raw.shape[1]:        # 防越界\n",
    "                segs.append(X_raw[:, st+win0:end])\n",
    "                labels.append(int(lab))\n",
    "    X = np.stack(segs).astype(np.float32)\n",
    "    y = np.array(labels, dtype=np.int64)\n",
    "    return X, y, fs\n",
    "\n",
    "def bandpass(X, lo, hi, fs, order=4):\n",
    "    b, a = butter(order, [lo/(fs/2), hi/(fs/2)], 'band')\n",
    "    return filtfilt(b, a, X, axis=-1, padlen=0)\n",
    "\n",
    "def zscore(X):\n",
    "    mu = X.mean(-1, keepdims=True); sd = X.std(-1, keepdims=True)\n",
    "    return (X - mu) / (sd + 1e-7)\n",
    "\n",
    "# ===============================================================\n",
    "# 2. 数据下载 & 读取  (以 A01T 为示例，高速镜像)\n",
    "# ===============================================================\n",
    "mat_file = 'A01T.mat'\n",
    "if not os.path.exists(mat_file):\n",
    "    url = 'https://www.bbci.de/competition/iv/desc_files/GDF/A01T.mat'\n",
    "    print('Downloading', url, '...')\n",
    "    urllib.request.urlretrieve(url, mat_file)\n",
    "\n",
    "X_raw, y, fs = load_bci_2a(mat_file)        # (288,22,1000)\n",
    "print(f\"Raw  : {X_raw.shape}  label 分布:\", np.bincount(y))\n",
    "\n",
    "# 8-30 Hz 带通 + 每通道 z-score\n",
    "X_proc = zscore(bandpass(X_raw, 8, 30, fs))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. 划分 train / val (8:2 stratified)\n",
    "# ---------------------------------------------------------------\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_proc, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "train_set = create_from_X_y(X_tr, y_tr, sfreq=fs, drop_last_window=False)\n",
    "val_set   = create_from_X_y(X_val, y_val, sfreq=fs, drop_last_window=False)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4.  定义模型 + EEGClassifier  ★只改下面这一小段★\n",
    "# ---------------------------------------------------------------\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model  = EEGNetv4(n_chans=22, n_outputs=4, n_times=X_tr.shape[-1])\n",
    "\n",
    "clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.CrossEntropyLoss,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        optimizer__lr=1e-3,\n",
    "        batch_size=16,\n",
    "        classes=[0, 1, 2, 3],            # ← 显式声明 4 个类别\n",
    "        train_split=predefined_split(val_set),\n",
    "        device=device,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. 训练                                   ← 只改这一行\n",
    "# ---------------------------------------------------------------\n",
    "clf.fit(train_set, epochs=30)                   # 不要再传 validation_set\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 6. 评估 + 混淆矩阵\n",
    "# ===============================================================\n",
    "y_pred = clf.predict(val_set)\n",
    "val_acc = (y_pred == y_val).mean() * 100\n",
    "print(f\"\\nValidation ACC : {val_acc:.2f} %  ({len(y_val)} trials)\")\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['LH', 'RH', 'Feet', 'Tongue'])\n",
    "disp.plot(cmap='viridis')\n",
    "plt.title('Validation confusion – A01 demo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEws5RB3Yk4s",
    "outputId": "99ea37ae-a1c6-4864-f0ff-19387656ad1c"
   },
   "outputs": [],
   "source": [
    "# ---------------- 仅改 SUBJ 即可 ----------------\n",
    "SUBJ = 'A02T'                 # 想测谁改谁\n",
    "# ------------------------------------------------\n",
    "import numpy as np, scipy.io as sio, lightgbm as lgb\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mne.decoding import CSP\n",
    "# ---------- 读取 ----------\n",
    "X_raw, y, fs = load_bci_2a(f'{SUBJ}.mat')        # ← 用之前函数\n",
    "# band-pass 8-30 Hz + z-score\n",
    "b,a  = butter(4,[8/(fs/2),30/(fs/2)],'band')\n",
    "X_bp = filtfilt(b,a,X_raw,axis=-1,padlen=0)\n",
    "X_z  = StandardScaler().fit_transform(\n",
    "          X_bp.reshape(-1,X_bp.shape[-1])\n",
    "       ).reshape(X_bp.shape)\n",
    "\n",
    "# ---------- FB-CSP ----------\n",
    "bands   = [(4,8),(8,12),(12,16),(16,20),(20,24),(24,30)]\n",
    "feats   = []\n",
    "for lo,hi in bands:\n",
    "    xb = filtfilt(*butter(4,[lo/(fs/2),hi/(fs/2)],'band'),\n",
    "                  X_z,axis=-1,padlen=0)\n",
    "    feats.append(CSP(n_components=6,log=True).fit_transform(xb,y))\n",
    "X_feat = np.concatenate(feats,1)        # (n_trial, 36)\n",
    "\n",
    "# ---------- LightGBM ----------\n",
    "clf = lgb.LGBMClassifier(\n",
    "        n_estimators=600, max_depth=5, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "cv  = StratifiedKFold(n_splits=6,shuffle=True,random_state=42)\n",
    "acc = cross_val_score(clf,X_feat,y,cv=cv,scoring='accuracy')\n",
    "print(f'{SUBJ}   6-fold ACC : {acc.mean()*100:.2f} ± {acc.std()*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzv01fJUZRv2"
   },
   "source": [
    "2 . 所有受试者合并 + ③ LOSO\n",
    "核心思路：\n",
    "① 把 9 人数据合在一起；\n",
    "② 用 Riemannian Alignment（Tangent Space）把协方差矩阵投到欧氏空间；\n",
    "③ 用 MDM（Minimum Distance to Mean）或简单 Logistic Regression 分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "4bb77c4de39c47fb961122aabb65d4dd",
      "45c4d6b89c284fccbfc5dd3a5df4b610",
      "b932a7a4f36648a2bec3b6e3c32112f1",
      "843ac449250f4602890a3b51a3c5fe63",
      "284360f509d8418fa97b5e1d9ea9a01d",
      "0c14f7f40f6a48ffaf50f0a7f1ea21a3",
      "3724fe84b3d24d179f281fb292ca9d16",
      "559c76e21e4645818a7062a0c7d9783a",
      "db7978e0b1db4472afb7115608b407f0",
      "d6c6fab3c8644ada844953dccf1223da",
      "25f99dccba24494bbe1588c0b19b7175"
     ]
    },
    "id": "yrIDWE_-bPka",
    "outputId": "65625ca2-9925-4b6a-9b0f-2da60401369c"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# STEP 0 ─ 安装 (0.7)  &  兜底检测\n",
    "# ===============================================================\n",
    "!pip -q install --upgrade mne==1.7.0 pyriemann==0.7 tqdm\n",
    "\n",
    "import importlib, sys, subprocess, json, types, warnings\n",
    "try:\n",
    "    importlib.import_module('pyriemann')\n",
    "except ModuleNotFoundError as e:\n",
    "    sys.exit('❌  pyriemann 仍未安装成功，请检查网络后重试。')\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 1 ─ 通用 import  & 工具函数\n",
    "# ===============================================================\n",
    "import os, urllib.request, numpy as np, scipy.io as sio\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.linalg import block_diag\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def load_bci_2a(mat_path, picks=22, t0=2.0, t1=6.0):\n",
    "    mat, segs, labels = sio.loadmat(mat_path), [], []\n",
    "    for sess in mat['data'][0]:\n",
    "        y_run = sess['y'].item().squeeze()\n",
    "        if y_run.size == 0:\n",
    "            continue\n",
    "        trials = sess['trial'].item().squeeze()\n",
    "        X_raw  = sess['X'].item().T[:picks]\n",
    "        fs     = int(sess['fs'].item())\n",
    "        w0, w1 = int(t0*fs), int(t1*fs)\n",
    "        for st, lb in zip(trials[y_run>0], y_run[y_run>0]-1):\n",
    "            if st + w1 <= X_raw.shape[1]:\n",
    "                segs.append(X_raw[:, st+w0: st+w1])\n",
    "                labels.append(int(lb))\n",
    "    return np.stack(segs).astype(np.float32), np.array(labels), fs\n",
    "\n",
    "def bandpass(X, lo, hi, fs, order=4):\n",
    "    b, a = butter(order, [lo/(fs/2), hi/(fs/2)], 'band')\n",
    "    return filtfilt(b, a, X, axis=-1, padlen=0)\n",
    "\n",
    "def zscore(X):\n",
    "    mu, sd = X.mean(-1, keepdims=True), X.std(-1, keepdims=True)\n",
    "    return (X - mu) / (sd + 1e-7)\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 2 ─ 合并 9 个受试者数据\n",
    "# ===============================================================\n",
    "subj_files = [f'A0{i}T.mat' for i in range(1,10)]\n",
    "dl_url     = 'https://www.bbci.de/competition/iv/desc_files/GDF/{}'\n",
    "\n",
    "Xs, ys, subs = [], [], []\n",
    "for f in subj_files:\n",
    "    if not os.path.exists(f):\n",
    "        print('⬇ downloading', f)\n",
    "        urllib.request.urlretrieve(dl_url.format(f), f)\n",
    "    X, y, fs = load_bci_2a(f)\n",
    "    Xs.append(X);  ys.append(y)\n",
    "    subs.append(np.full(y.shape, f[:3], dtype='<U3'))\n",
    "\n",
    "X_all = np.concatenate(Xs)          # (2592,22,1000)\n",
    "y_all = np.concatenate(ys)\n",
    "subs   = np.concatenate(subs)\n",
    "print('合并后 shape:', X_all.shape, ' label 计数:', np.bincount(y_all))\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 3 ─ 频带协方差 → （可选）对齐 → Tangent Space\n",
    "# ===============================================================\n",
    "from pyriemann.estimation   import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "# ---- 尝试导入对齐模块 ----\n",
    "aligner = None\n",
    "try:                                      # v0.8 路径\n",
    "    from pyriemann.alignment import ProcrustesAlignment\n",
    "    aligner = ProcrustesAlignment()\n",
    "except ModuleNotFoundError:\n",
    "    try:                                  # v0.7 及以下路径\n",
    "        from pyriemann.utils.alignment import ProcrustesAlignment\n",
    "        aligner = ProcrustesAlignment()\n",
    "    except ModuleNotFoundError:\n",
    "        warnings.warn('⚠️  未找到对齐模块，直接使用未对齐协方差')\n",
    "        aligner = None\n",
    "\n",
    "fbands = [(4,8),(8,12),(12,16),(16,20),(20,24),(24,28),(28,32),(32,40)]\n",
    "print(f'共 {len(fbands)} 个频带:', fbands)\n",
    "\n",
    "print('⏳ 计算协方差 / block-diag …')\n",
    "cov_blocks = []\n",
    "for lo, hi in tqdm(fbands):\n",
    "    Xb   = zscore(bandpass(X_all, lo, hi, fs))\n",
    "    covs = Covariances(estimator='oas').fit_transform(Xb)   # (N,22,22)\n",
    "    cov_blocks.append(covs)\n",
    "\n",
    "covs_block = np.array([block_diag(*cov_trial)\n",
    "                       for cov_trial in zip(*cov_blocks)])  # (N,22*B,22*B)\n",
    "\n",
    "if aligner is not None:\n",
    "    covs_block = aligner.fit_transform(covs_block)\n",
    "\n",
    "ts = TangentSpace().fit_transform(covs_block)\n",
    "print('Tangent Space shape:', ts.shape)\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 4 ─ SVC 分类 & 评估\n",
    "# ===============================================================\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "svc = SVC(kernel='rbf', C=2, gamma='scale')\n",
    "\n",
    "# 10-fold\n",
    "cv10  = StratifiedKFold(10, shuffle=True, random_state=42)\n",
    "acc10 = [svc.fit(ts[tr], y_all[tr]).score(ts[te], y_all[te])*100\n",
    "         for tr, te in cv10.split(ts, y_all)]\n",
    "print(f'\\n★ FB-TS {\"+Alignment \" if aligner else \"\"}10-fold : '\n",
    "      f'{np.mean(acc10):.2f} ± {np.std(acc10):.2f} %')\n",
    "\n",
    "# LOSO\n",
    "acc_loso = []\n",
    "print('\\n★ LOSO 结果：')\n",
    "for sid in np.unique(subs):\n",
    "    tr, te = subs != sid, subs == sid\n",
    "    svc.fit(ts[tr], y_all[tr])\n",
    "    acc = svc.score(ts[te], y_all[te])*100\n",
    "    acc_loso.append(acc)\n",
    "    print(f'  {sid}: {acc:.2f} %  ({te.sum()} trials)')\n",
    "\n",
    "print(f'\\n★ FB-TS {\"+Alignment \" if aligner else \"\"}LOSO : '\n",
    "      f'{np.mean(acc_loso):.2f} ± {np.std(acc_loso):.2f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2FXRMWtEevH"
   },
   "source": [
    "合并后 shape: (2592, 22, 1000)  label 计数: [648 648 648 648]\n",
    "共 8 个频带: [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 40)]\n",
    "⏳ 计算协方差 / block-diag …\n",
    "100%\n",
    " 8/8 [00:56<00:00,  6.64s/it]\n",
    "Tangent Space shape: (2592, 15576)\n",
    "\n",
    "★ FB-TS 10-fold : 61.73 ± 3.54 %\n",
    "\n",
    "★ LOSO 结果：\n",
    "  A01: 36.81 %  (288 trials)\n",
    "  A02: 27.43 %  (288 trials)\n",
    "  A03: 36.46 %  (288 trials)\n",
    "  A04: 31.60 %  (288 trials)\n",
    "  A05: 28.47 %  (288 trials)\n",
    "  A06: 31.25 %  (288 trials)\n",
    "  A07: 27.78 %  (288 trials)\n",
    "  A08: 34.72 %  (288 trials)\n",
    "  A09: 28.47 %  (288 trials)\n",
    "\n",
    "★ FB-TS LOSO : 31.44 ± 3.53 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYm8fiOvGXG9"
   },
   "source": [
    "为什么分数仍然不高？\n",
    "环节\t目前做法\t典型改进方向\n",
    "协方差估计\tOAS（单试次）\t多试次平均、Riemannian Shrinkage、XDAWN+Cov\n",
    "对齐\t未启用（v0.7 没有 alignment 模块）\tWhitening/Procrustes Alignment（需 v0.8+，或自己实现）\n",
    "特征维数\t15 576 维全部保留\tFB 共形、Log-Euclid 映射后 PCA / SPoC 降到 < 1 000 维\n",
    "分类器\tRBF-SVC (默认 γ)\tLogReg / LightGBM / CSP + GBDT 组合\n",
    "数据均衡\t原始 4 类均衡\t在 LOSO 设置下对目标被试做 Riemannian Alignment + 少量标注微调\n",
    "\n",
    "如果想继续提升\n",
    "升级到 pyriemann 0.8.1 本地环境（或者源码安装）以启用\n",
    "\n",
    "python\n",
    "复制\n",
    "编辑\n",
    "from pyriemann.alignment import WhiteningAlignment\n",
    "covs_block = WhiteningAlignment().fit_transform(covs_block)\n",
    "典型可把 LOSO 提到 ~40 %。\n",
    "\n",
    "在 Step 3 加入 PCA(95 %) 再跑 SVC，或直接用之前的 PCA + LogReg pipeline —— 等同于 “对齐 + 降维 + 线性分类”。\n",
    "\n",
    "参考你最早跑通的 单人 FB-CSP + LightGBM 方案，把每个频带的 CSP 特征（6×8 = 48 维）叠加，再用 GBDT；LOSO 前先做 Procrustes Alignment 往往能到 35 % - 45 %。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51BddiFtEhRl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "欢迎使用 Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
